{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f5c01f97cadf4e15aff9604b4f3b61a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35528e069a944698a60ea2aab06382c8","IPY_MODEL_09914055e34243259d37018cf19895f5","IPY_MODEL_581a8e314c144b1cba07dbcaeb748ab4"],"layout":"IPY_MODEL_6c5bc52d21a54f5784e9d3079e8b8e6c"}},"35528e069a944698a60ea2aab06382c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58b5382c203b4c23b1b96cc48f723164","placeholder":"​","style":"IPY_MODEL_86658a672b81468a84a65360d1d3e149","value":"tokenizer_config.json: 100%"}},"09914055e34243259d37018cf19895f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d3a340dfd1647ef8952ff1b97d57c4e","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aac47569ad2a4ba8869419b1e1b390fa","value":48}},"581a8e314c144b1cba07dbcaeb748ab4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e601557b4b0149ec96e5ab36852e6760","placeholder":"​","style":"IPY_MODEL_e89d33aeda4e4b16b03ff574010d021d","value":" 48.0/48.0 [00:00&lt;00:00, 2.39kB/s]"}},"6c5bc52d21a54f5784e9d3079e8b8e6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58b5382c203b4c23b1b96cc48f723164":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86658a672b81468a84a65360d1d3e149":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d3a340dfd1647ef8952ff1b97d57c4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aac47569ad2a4ba8869419b1e1b390fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e601557b4b0149ec96e5ab36852e6760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e89d33aeda4e4b16b03ff574010d021d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0eec484539c64150aed06500034ef931":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8175e0aa41fe4ac580134761a06eb0a3","IPY_MODEL_f4ab7553adf64365ab6f16368d826853","IPY_MODEL_2a2001fe6e474192879100a9aa318992"],"layout":"IPY_MODEL_2daf29bfd9d3495f9d613f521dc83f73"}},"8175e0aa41fe4ac580134761a06eb0a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6f5820bff194ee6af82665e3237cc10","placeholder":"​","style":"IPY_MODEL_1e538b2f416149a99ff00caef7f7137e","value":"config.json: 100%"}},"f4ab7553adf64365ab6f16368d826853":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb77591d53494fabb31894ff1e77f736","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8aa4498aa1214ad596c25c399335df63","value":570}},"2a2001fe6e474192879100a9aa318992":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e68cb3f216c4a8894aef8d807beba45","placeholder":"​","style":"IPY_MODEL_c3ef328f5acf465ab3d7d18fe4fd4e0c","value":" 570/570 [00:00&lt;00:00, 31.9kB/s]"}},"2daf29bfd9d3495f9d613f521dc83f73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6f5820bff194ee6af82665e3237cc10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e538b2f416149a99ff00caef7f7137e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb77591d53494fabb31894ff1e77f736":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8aa4498aa1214ad596c25c399335df63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e68cb3f216c4a8894aef8d807beba45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ef328f5acf465ab3d7d18fe4fd4e0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"312ef18779ad4451ab483de36b40bb9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a10c57a8971441958b5fd6af71e2c83d","IPY_MODEL_7e20209c9702443ab78da9e45f4994c4","IPY_MODEL_a8bc3a7e57754ea88d8dd923f0b83b4f"],"layout":"IPY_MODEL_59ecea3442ca4fbf87a9b8194452e3e6"}},"a10c57a8971441958b5fd6af71e2c83d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d97d5c50a1549d3befa53f56f9125df","placeholder":"​","style":"IPY_MODEL_82d615166e414161add60614b7830142","value":"vocab.txt: 100%"}},"7e20209c9702443ab78da9e45f4994c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83d775f4a4bf43489375c263263130eb","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b013b6b23b044380b58275553240e5a8","value":231508}},"a8bc3a7e57754ea88d8dd923f0b83b4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8aee889055e4b42982b3ca4f2f07a77","placeholder":"​","style":"IPY_MODEL_03df3d7ee69741f2bf659a5ca65a18cf","value":" 232k/232k [00:00&lt;00:00, 2.67MB/s]"}},"59ecea3442ca4fbf87a9b8194452e3e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d97d5c50a1549d3befa53f56f9125df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82d615166e414161add60614b7830142":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83d775f4a4bf43489375c263263130eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b013b6b23b044380b58275553240e5a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f8aee889055e4b42982b3ca4f2f07a77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03df3d7ee69741f2bf659a5ca65a18cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19ff5010dc104c02ae6ffad3d1cad9dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f667423fd5747a89bec058416bf6325","IPY_MODEL_ab61d46c49c04443b2b1d093ad3cc399","IPY_MODEL_dac4e4b05bc44849b4b1e99c3a0575f2"],"layout":"IPY_MODEL_89c1974a77f344159b675dd9d87bbac6"}},"2f667423fd5747a89bec058416bf6325":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32dad3e061ba404c8966f68d823c33db","placeholder":"​","style":"IPY_MODEL_8db101f9b1ad4f288725b43ce4bb88fb","value":"tokenizer.json: 100%"}},"ab61d46c49c04443b2b1d093ad3cc399":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2639f10a7c4a4387bcb9dc3fa7567bd4","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a9d2e7422b04819a6e90c766321cbcd","value":466062}},"dac4e4b05bc44849b4b1e99c3a0575f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a81d0de4a596415792d6d0c7f3aa6d35","placeholder":"​","style":"IPY_MODEL_d1596269203441bcaaf5c744f4abe754","value":" 466k/466k [00:00&lt;00:00, 10.4MB/s]"}},"89c1974a77f344159b675dd9d87bbac6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32dad3e061ba404c8966f68d823c33db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8db101f9b1ad4f288725b43ce4bb88fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2639f10a7c4a4387bcb9dc3fa7567bd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a9d2e7422b04819a6e90c766321cbcd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a81d0de4a596415792d6d0c7f3aa6d35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1596269203441bcaaf5c744f4abe754":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c22b0b67f6c475eb17f778b5740a371":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e3a7bdd95784996844c25429cebbe84","IPY_MODEL_4653ceb774154707b4faee84ab179615","IPY_MODEL_8cda1f7f24b745548baba7c82614726b"],"layout":"IPY_MODEL_f22f3524b0914fe0a914daf4dc3a94ca"}},"2e3a7bdd95784996844c25429cebbe84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f85f4671ad834c5d98ba5fae116efbc3","placeholder":"​","style":"IPY_MODEL_41c4462942d7497cbe2e9fe8b29a4314","value":"Map: 100%"}},"4653ceb774154707b4faee84ab179615":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_943c39c773014b8596983b515efa7eb3","max":7613,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61f130aff7714a9b88e3d93103bbcec1","value":7613}},"8cda1f7f24b745548baba7c82614726b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f17a9174dafd40c08983c11cfe6fa21b","placeholder":"​","style":"IPY_MODEL_d678aafb09fb4a88b80c2ca70e98d9ec","value":" 7613/7613 [00:01&lt;00:00, 6589.17 examples/s]"}},"f22f3524b0914fe0a914daf4dc3a94ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f85f4671ad834c5d98ba5fae116efbc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41c4462942d7497cbe2e9fe8b29a4314":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"943c39c773014b8596983b515efa7eb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61f130aff7714a9b88e3d93103bbcec1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f17a9174dafd40c08983c11cfe6fa21b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d678aafb09fb4a88b80c2ca70e98d9ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6503b91b867843a89d9775281ad0105c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfe91979a43b4601b625c5472355edf3","IPY_MODEL_0e3084c1a8c84255bec7afd1dd399c18","IPY_MODEL_57fbe0ed253846a2b2a356e4a8750837"],"layout":"IPY_MODEL_75dd976fd2dc41078eec28678b0de6b6"}},"dfe91979a43b4601b625c5472355edf3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ebbb94b3d7547d4a90cd30a00e74180","placeholder":"​","style":"IPY_MODEL_3ab85b55f1794d4f818bbff8baab26be","value":"model.safetensors: 100%"}},"0e3084c1a8c84255bec7afd1dd399c18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f4e2004e0df4bc89459a4ee644495cb","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ea955d9dc85439bbe07233449d8353e","value":440449768}},"57fbe0ed253846a2b2a356e4a8750837":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4d4c69868d049ee9c9535bc6c5a985c","placeholder":"​","style":"IPY_MODEL_b1acdb383acd4d8bab630755c89ace77","value":" 440M/440M [00:03&lt;00:00, 116MB/s]"}},"75dd976fd2dc41078eec28678b0de6b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ebbb94b3d7547d4a90cd30a00e74180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ab85b55f1794d4f818bbff8baab26be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f4e2004e0df4bc89459a4ee644495cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ea955d9dc85439bbe07233449d8353e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e4d4c69868d049ee9c9535bc6c5a985c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1acdb383acd4d8bab630755c89ace77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AdamW\nimport torch","metadata":{"id":"TKDjjTGzNe7h","execution":{"iopub.status.busy":"2024-10-08T17:00:04.646317Z","iopub.execute_input":"2024-10-08T17:00:04.646678Z","iopub.status.idle":"2024-10-08T17:00:12.654079Z","shell.execute_reply.started":"2024-10-08T17:00:04.646637Z","shell.execute_reply":"2024-10-08T17:00:12.653187Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nimport re","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3LPhDWh7MOyR","outputId":"28d748c7-f6ee-4141-c841-0f36ad47d5e4","execution":{"iopub.status.busy":"2024-10-08T17:00:12.656322Z","iopub.execute_input":"2024-10-08T17:00:12.656865Z","iopub.status.idle":"2024-10-08T17:00:14.520186Z","shell.execute_reply.started":"2024-10-08T17:00:12.656819Z","shell.execute_reply":"2024-10-08T17:00:14.519035Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F0c5DAzvM0mQ","outputId":"6e486e2c-54aa-4eda-ef51-80ff29c69228","execution":{"iopub.status.busy":"2024-10-08T17:00:14.521550Z","iopub.execute_input":"2024-10-08T17:00:14.522079Z","iopub.status.idle":"2024-10-08T17:00:14.586667Z","shell.execute_reply.started":"2024-10-08T17:00:14.522018Z","shell.execute_reply":"2024-10-08T17:00:14.585697Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')","metadata":{"id":"xX8A486qNGUd","execution":{"iopub.status.busy":"2024-10-08T17:00:14.588139Z","iopub.execute_input":"2024-10-08T17:00:14.589261Z","iopub.status.idle":"2024-10-08T17:00:15.023445Z","shell.execute_reply.started":"2024-10-08T17:00:14.589212Z","shell.execute_reply":"2024-10-08T17:00:15.019676Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ojuw7bbaNyni","outputId":"1b7b0bf4-cad3-4855-819d-7438d51ec951","execution":{"iopub.status.busy":"2024-10-08T17:00:15.025978Z","iopub.execute_input":"2024-10-08T17:00:15.026695Z","iopub.status.idle":"2024-10-08T17:00:15.052685Z","shell.execute_reply.started":"2024-10-08T17:00:15.026647Z","shell.execute_reply":"2024-10-08T17:00:15.051764Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nsw = stopwords.words('english')\n\ndef clean_text(text):\n\n    text = text.lower()\n\n    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text)\n    text = re.sub(r\"http\\S+\", \"\",text)\n    html=re.compile(r'<.*?>')\n    text = html.sub(r'',text)\n\n    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n    for p in punctuations:\n        text = text.replace(p,'')\n\n    text = [word.lower() for word in text.split() if word.lower() not in sw]\n\n    text = \" \".join(text)\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"\n                           u\"\\U0001F300-\\U0001F5FF\"\n                           u\"\\U0001F680-\\U0001F6FF\"\n                           u\"\\U0001F1E0-\\U0001F1FF\"\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text)\n    return text","metadata":{"id":"nvQlAoy5Nzmf","execution":{"iopub.status.busy":"2024-10-08T17:00:15.053896Z","iopub.execute_input":"2024-10-08T17:00:15.054283Z","iopub.status.idle":"2024-10-08T17:00:15.067780Z","shell.execute_reply.started":"2024-10-08T17:00:15.054240Z","shell.execute_reply":"2024-10-08T17:00:15.066869Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['text'].apply(clean_text)","metadata":{"id":"jIRr41aMOK7q","execution":{"iopub.status.busy":"2024-10-08T17:00:15.068750Z","iopub.execute_input":"2024-10-08T17:00:15.069096Z","iopub.status.idle":"2024-10-08T17:00:15.556666Z","shell.execute_reply.started":"2024-10-08T17:00:15.069036Z","shell.execute_reply":"2024-10-08T17:00:15.555818Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns=['id','keyword','location'], axis=1)","metadata":{"id":"RMunmM32Yke7","execution":{"iopub.status.busy":"2024-10-08T17:00:15.900000Z","iopub.execute_input":"2024-10-08T17:00:15.900629Z","iopub.status.idle":"2024-10-08T17:00:15.912528Z","shell.execute_reply.started":"2024-10-08T17:00:15.900583Z","shell.execute_reply":"2024-10-08T17:00:15.911613Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"MCI3SgvvY1wt","outputId":"2f4b886e-3b36-492a-babc-7d3166259d76","execution":{"iopub.status.busy":"2024-10-08T17:00:17.178156Z","iopub.execute_input":"2024-10-08T17:00:17.178893Z","iopub.status.idle":"2024-10-08T17:00:17.192337Z","shell.execute_reply.started":"2024-10-08T17:00:17.178854Z","shell.execute_reply":"2024-10-08T17:00:17.191371Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                   text  target\n0          deeds reason earthquake may allah forgive us       1\n1                 forest fire near la ronge sask canada       1\n2     residents asked shelter place notified officer...       1\n3     , people receive wildfires evacuation orders c...       1\n4     got sent photo ruby alaska smoke wildfires pou...       1\n...                                                 ...     ...\n7608  two giant cranes holding bridge collapse nearb...       1\n7609  aria ahrary thetawniest control wild fires cal...       1\n7610          utc km volcano hawaii http tco zdtoyd ebj       1\n7611  police investigating e bike collided car littl...       1\n7612  latest homes razed northern california wildfir...       1\n\n[7613 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>deeds reason earthquake may allah forgive us</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>forest fire near la ronge sask canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>residents asked shelter place notified officer...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>, people receive wildfires evacuation orders c...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>two giant cranes holding bridge collapse nearb...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>aria ahrary thetawniest control wild fires cal...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>utc km volcano hawaii http tco zdtoyd ebj</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>police investigating e bike collided car littl...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>latest homes razed northern california wildfir...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7613 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install -q datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JVL0p7Z8ZqjV","outputId":"a87d0ef4-67d7-40bb-cb9d-777c07695e5e","execution":{"iopub.status.busy":"2024-10-08T17:00:24.366002Z","iopub.execute_input":"2024-10-08T17:00:24.366390Z","iopub.status.idle":"2024-10-08T17:00:37.861539Z","shell.execute_reply.started":"2024-10-08T17:00:24.366347Z","shell.execute_reply":"2024-10-08T17:00:37.860420Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ndataset = Dataset.from_pandas(df[['text', 'target']])","metadata":{"id":"i05NQ3f8Ziiv","execution":{"iopub.status.busy":"2024-10-08T17:00:37.863605Z","iopub.execute_input":"2024-10-08T17:00:37.863949Z","iopub.status.idle":"2024-10-08T17:00:38.614535Z","shell.execute_reply.started":"2024-10-08T17:00:37.863914Z","shell.execute_reply":"2024-10-08T17:00:38.613752Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k_Rlii7FZz5R","outputId":"c97c175c-a2b3-4787-d8b2-444322a8454b","execution":{"iopub.status.busy":"2024-10-08T17:00:38.615684Z","iopub.execute_input":"2024-10-08T17:00:38.616145Z","iopub.status.idle":"2024-10-08T17:00:38.623431Z","shell.execute_reply.started":"2024-10-08T17:00:38.616109Z","shell.execute_reply":"2024-10-08T17:00:38.622528Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'target'],\n    num_rows: 7613\n})"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309,"referenced_widgets":["f5c01f97cadf4e15aff9604b4f3b61a6","35528e069a944698a60ea2aab06382c8","09914055e34243259d37018cf19895f5","581a8e314c144b1cba07dbcaeb748ab4","6c5bc52d21a54f5784e9d3079e8b8e6c","58b5382c203b4c23b1b96cc48f723164","86658a672b81468a84a65360d1d3e149","6d3a340dfd1647ef8952ff1b97d57c4e","aac47569ad2a4ba8869419b1e1b390fa","e601557b4b0149ec96e5ab36852e6760","e89d33aeda4e4b16b03ff574010d021d","0eec484539c64150aed06500034ef931","8175e0aa41fe4ac580134761a06eb0a3","f4ab7553adf64365ab6f16368d826853","2a2001fe6e474192879100a9aa318992","2daf29bfd9d3495f9d613f521dc83f73","d6f5820bff194ee6af82665e3237cc10","1e538b2f416149a99ff00caef7f7137e","fb77591d53494fabb31894ff1e77f736","8aa4498aa1214ad596c25c399335df63","5e68cb3f216c4a8894aef8d807beba45","c3ef328f5acf465ab3d7d18fe4fd4e0c","312ef18779ad4451ab483de36b40bb9f","a10c57a8971441958b5fd6af71e2c83d","7e20209c9702443ab78da9e45f4994c4","a8bc3a7e57754ea88d8dd923f0b83b4f","59ecea3442ca4fbf87a9b8194452e3e6","3d97d5c50a1549d3befa53f56f9125df","82d615166e414161add60614b7830142","83d775f4a4bf43489375c263263130eb","b013b6b23b044380b58275553240e5a8","f8aee889055e4b42982b3ca4f2f07a77","03df3d7ee69741f2bf659a5ca65a18cf","19ff5010dc104c02ae6ffad3d1cad9dc","2f667423fd5747a89bec058416bf6325","ab61d46c49c04443b2b1d093ad3cc399","dac4e4b05bc44849b4b1e99c3a0575f2","89c1974a77f344159b675dd9d87bbac6","32dad3e061ba404c8966f68d823c33db","8db101f9b1ad4f288725b43ce4bb88fb","2639f10a7c4a4387bcb9dc3fa7567bd4","2a9d2e7422b04819a6e90c766321cbcd","a81d0de4a596415792d6d0c7f3aa6d35","d1596269203441bcaaf5c744f4abe754"]},"id":"lqUCKiyEPzln","outputId":"c47e6473-625a-4ca5-f966-e1dad2994298","execution":{"iopub.status.busy":"2024-10-08T17:00:38.625939Z","iopub.execute_input":"2024-10-08T17:00:38.626231Z","iopub.status.idle":"2024-10-08T17:00:39.658563Z","shell.execute_reply.started":"2024-10-08T17:00:38.626200Z","shell.execute_reply":"2024-10-08T17:00:39.657615Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a4f5d4d6b7f495590cd4b17e132f5ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8baa9848c0b84c6b9e10e4c8efd08e41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47c518ed082456bb99f479b67c8fba2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89888bcb4145462ab1e742fffe8586dd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"max_length=0\nfor tweet in dataset['text']:\n    length = len(tweet)\n    if length > max_length:\n        max_length = length\nprint(length)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"baaPOammemxX","outputId":"7b125b8f-acbf-46e7-a596-b81255aa0bad","execution":{"iopub.status.busy":"2024-10-08T17:00:39.659667Z","iopub.execute_input":"2024-10-08T17:00:39.659952Z","iopub.status.idle":"2024-10-08T17:00:39.681919Z","shell.execute_reply.started":"2024-10-08T17:00:39.659922Z","shell.execute_reply":"2024-10-08T17:00:39.681028Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"74\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        pad_to_max_length=True,\n        padding='max_length',\n        truncation=True,\n        max_length=45,\n        return_token_type_ids=False,\n        return_attention_mask=True,\n        return_tensors='pt'\n    )\ntokenized_dataset = dataset.map(tokenize_function, batched=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["4c22b0b67f6c475eb17f778b5740a371","2e3a7bdd95784996844c25429cebbe84","4653ceb774154707b4faee84ab179615","8cda1f7f24b745548baba7c82614726b","f22f3524b0914fe0a914daf4dc3a94ca","f85f4671ad834c5d98ba5fae116efbc3","41c4462942d7497cbe2e9fe8b29a4314","943c39c773014b8596983b515efa7eb3","61f130aff7714a9b88e3d93103bbcec1","f17a9174dafd40c08983c11cfe6fa21b","d678aafb09fb4a88b80c2ca70e98d9ec"]},"id":"x76Zq1nlds32","outputId":"e161d95a-692b-44f9-cd5b-cd3d71527699","execution":{"iopub.status.busy":"2024-10-08T17:00:39.683211Z","iopub.execute_input":"2024-10-08T17:00:39.683510Z","iopub.status.idle":"2024-10-08T17:00:40.420723Z","shell.execute_reply.started":"2024-10-08T17:00:39.683478Z","shell.execute_reply":"2024-10-08T17:00:40.419804Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7613 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8fc40d9c7e0459d9a240c892ca0b87e"}},"metadata":{}}]},{"cell_type":"code","source":"train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\ntrain_dataset = train_test_split['train']\nval_dataset = train_test_split['test']","metadata":{"id":"Y9ipa2K4Z1oN","execution":{"iopub.status.busy":"2024-10-08T17:00:40.421889Z","iopub.execute_input":"2024-10-08T17:00:40.422221Z","iopub.status.idle":"2024-10-08T17:00:40.439737Z","shell.execute_reply.started":"2024-10-08T17:00:40.422186Z","shell.execute_reply":"2024-10-08T17:00:40.438914Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_dataset.rename_column(\"target\", \"labels\")\nval_dataset = val_dataset.rename_column(\"target\", \"labels\")","metadata":{"id":"udpf1yz1khvk","execution":{"iopub.status.busy":"2024-10-08T17:00:40.440835Z","iopub.execute_input":"2024-10-08T17:00:40.441155Z","iopub.status.idle":"2024-10-08T17:00:40.450298Z","shell.execute_reply.started":"2024-10-08T17:00:40.441122Z","shell.execute_reply":"2024-10-08T17:00:40.449109Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugOkW00yaNxm","outputId":"9b2a6ef3-1c6a-4c90-a158-9c7635632b95","execution":{"iopub.status.busy":"2024-10-08T17:00:40.451565Z","iopub.execute_input":"2024-10-08T17:00:40.452012Z","iopub.status.idle":"2024-10-08T17:00:40.460646Z","shell.execute_reply.started":"2024-10-08T17:00:40.451966Z","shell.execute_reply":"2024-10-08T17:00:40.459727Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n    num_rows: 6090\n})"},"metadata":{}}]},{"cell_type":"code","source":"val_dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzYv9L1GaQeU","outputId":"f18a78a6-a4f0-4654-d91f-468f9ceb18b1","execution":{"iopub.status.busy":"2024-10-08T17:00:40.465227Z","iopub.execute_input":"2024-10-08T17:00:40.465615Z","iopub.status.idle":"2024-10-08T17:00:40.473002Z","shell.execute_reply.started":"2024-10-08T17:00:40.465577Z","shell.execute_reply":"2024-10-08T17:00:40.471562Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n    num_rows: 1523\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset = train_dataset.remove_columns(['text'])\nval_dataset = val_dataset.remove_columns(['text'])","metadata":{"id":"JDuCfBA7gmyA","execution":{"iopub.status.busy":"2024-10-08T17:00:40.474456Z","iopub.execute_input":"2024-10-08T17:00:40.474952Z","iopub.status.idle":"2024-10-08T17:00:40.485265Z","shell.execute_reply.started":"2024-10-08T17:00:40.474902Z","shell.execute_reply":"2024-10-08T17:00:40.484192Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"id":"OCju_rpNaph1","execution":{"iopub.status.busy":"2024-10-08T17:00:40.487273Z","iopub.execute_input":"2024-10-08T17:00:40.487735Z","iopub.status.idle":"2024-10-08T17:00:58.822618Z","shell.execute_reply.started":"2024-10-08T17:00:40.487658Z","shell.execute_reply":"2024-10-08T17:00:58.821641Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, Trainer, TrainingArguments","metadata":{"id":"6--hVPdtUBhC","execution":{"iopub.status.busy":"2024-10-08T17:00:58.823902Z","iopub.execute_input":"2024-10-08T17:00:58.824698Z","iopub.status.idle":"2024-10-08T17:01:00.880031Z","shell.execute_reply.started":"2024-10-08T17:00:58.824653Z","shell.execute_reply":"2024-10-08T17:01:00.879245Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def model_init(trial):\n    return BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, output_attentions=False,\n    output_hidden_states=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:01:00.881068Z","iopub.execute_input":"2024-10-08T17:01:00.881642Z","iopub.status.idle":"2024-10-08T17:01:00.886621Z","shell.execute_reply.started":"2024-10-08T17:01:00.881608Z","shell.execute_reply":"2024-10-08T17:01:00.885320Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    warmup_steps=500,\n    logging_dir='./logs',\n    logging_steps=100,\n    eval_strategy='steps',\n    eval_steps=100,\n    save_steps=100,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    report_to='none'\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__tWAMEAU5Qj","outputId":"045f6b38-1232-4603-9d4a-f75a002cd217","execution":{"iopub.status.busy":"2024-10-08T17:01:00.887943Z","iopub.execute_input":"2024-10-08T17:01:00.888423Z","iopub.status.idle":"2024-10-08T17:01:00.964784Z","shell.execute_reply.started":"2024-10-08T17:01:00.888357Z","shell.execute_reply":"2024-10-08T17:01:00.963984Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1, \n        'precision': precision,\n        'recall': recall\n    }\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:01:00.965866Z","iopub.execute_input":"2024-10-08T17:01:00.966170Z","iopub.status.idle":"2024-10-08T17:01:00.972593Z","shell.execute_reply.started":"2024-10-08T17:01:00.966139Z","shell.execute_reply":"2024-10-08T17:01:00.971633Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=None,\n    model_init=model_init,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)","metadata":{"id":"v7rrdzniVnZH","execution":{"iopub.status.busy":"2024-10-08T17:01:00.973766Z","iopub.execute_input":"2024-10-08T17:01:00.974094Z","iopub.status.idle":"2024-10-08T17:01:03.829544Z","shell.execute_reply.started":"2024-10-08T17:01:00.974033Z","shell.execute_reply":"2024-10-08T17:01:03.828475Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"036783c07d7642f89c1e34fc1c963736"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install optuna","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:01:03.831032Z","iopub.execute_input":"2024-10-08T17:01:03.831762Z","iopub.status.idle":"2024-10-08T17:01:15.515036Z","shell.execute_reply.started":"2024-10-08T17:01:03.831714Z","shell.execute_reply":"2024-10-08T17:01:15.513897Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (4.0.0)\nRequirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.13.3)\nRequirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (21.3)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.30)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.66.4)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"def optuna_hp_space(trial):\n    return {\n        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True),\n        'per_device_train_batch_size': trial.suggest_categorical('per_device_train_batch_size', [16, 32]),\n        'per_device_eval_batch_size': trial.suggest_categorical('per_device_eval_batch_size', [16, 32]),\n        'num_train_epochs': trial.suggest_int('num_train_epochs', 2, 4),\n        'weight_decay': trial.suggest_float('weight_decay', 0.1, 0.3)\n    }","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:01:15.516812Z","iopub.execute_input":"2024-10-08T17:01:15.517261Z","iopub.status.idle":"2024-10-08T17:01:15.525323Z","shell.execute_reply.started":"2024-10-08T17:01:15.517215Z","shell.execute_reply":"2024-10-08T17:01:15.524406Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def compute_objective(metrics):\n    return metrics[\"eval_accuracy\"] ","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:01:15.526516Z","iopub.execute_input":"2024-10-08T17:01:15.526828Z","iopub.status.idle":"2024-10-08T17:01:15.537950Z","shell.execute_reply.started":"2024-10-08T17:01:15.526796Z","shell.execute_reply":"2024-10-08T17:01:15.537181Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"best_trials = trainer.hyperparameter_search(\n    direction='maximize',\n    backend=\"optuna\",\n    hp_space=optuna_hp_space,\n    n_trials=5,\n    compute_objective=compute_objective,\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-10-08T17:01:15.539088Z","iopub.execute_input":"2024-10-08T17:01:15.539486Z","iopub.status.idle":"2024-10-08T17:15:04.766133Z","shell.execute_reply.started":"2024-10-08T17:01:15.539453Z","shell.execute_reply":"2024-10-08T17:15:04.765306Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"[I 2024-10-08 17:01:15,753] A new study created in memory with name: no-name-dfb24c6f-c026-4883-9f32-45212613199b\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='764' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [764/764 03:34, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.634500</td>\n      <td>0.525384</td>\n      <td>0.751149</td>\n      <td>0.726748</td>\n      <td>0.687585</td>\n      <td>0.770642</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.462800</td>\n      <td>0.442042</td>\n      <td>0.804334</td>\n      <td>0.769706</td>\n      <td>0.778125</td>\n      <td>0.761468</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.406300</td>\n      <td>0.436850</td>\n      <td>0.820749</td>\n      <td>0.779305</td>\n      <td>0.826758</td>\n      <td>0.737003</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.379400</td>\n      <td>0.464576</td>\n      <td>0.822718</td>\n      <td>0.780488</td>\n      <td>0.833333</td>\n      <td>0.733945</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.323400</td>\n      <td>0.428270</td>\n      <td>0.820092</td>\n      <td>0.783570</td>\n      <td>0.810458</td>\n      <td>0.758410</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.327700</td>\n      <td>0.591030</td>\n      <td>0.816809</td>\n      <td>0.764954</td>\n      <td>0.851782</td>\n      <td>0.694190</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.218200</td>\n      <td>0.495416</td>\n      <td>0.822062</td>\n      <td>0.783026</td>\n      <td>0.821849</td>\n      <td>0.747706</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[I 2024-10-08 17:04:54,697] Trial 0 finished with value: 0.8220617202889035 and parameters: {'learning_rate': 4.171479503407097e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'num_train_epochs': 4, 'weight_decay': 0.1395962005551185}. Best is trial 0 with value: 0.8220617202889035.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='764' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [764/764 03:36, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.649100</td>\n      <td>0.557748</td>\n      <td>0.732108</td>\n      <td>0.706897</td>\n      <td>0.666667</td>\n      <td>0.752294</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.480600</td>\n      <td>0.462656</td>\n      <td>0.794485</td>\n      <td>0.766940</td>\n      <td>0.747460</td>\n      <td>0.787462</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.412600</td>\n      <td>0.421935</td>\n      <td>0.826658</td>\n      <td>0.782537</td>\n      <td>0.848214</td>\n      <td>0.726300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.379300</td>\n      <td>0.450321</td>\n      <td>0.820092</td>\n      <td>0.775777</td>\n      <td>0.834507</td>\n      <td>0.724771</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.328400</td>\n      <td>0.430183</td>\n      <td>0.826001</td>\n      <td>0.786118</td>\n      <td>0.832479</td>\n      <td>0.744648</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.327500</td>\n      <td>0.511029</td>\n      <td>0.820749</td>\n      <td>0.776046</td>\n      <td>0.837168</td>\n      <td>0.723242</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.224500</td>\n      <td>0.509201</td>\n      <td>0.813526</td>\n      <td>0.773885</td>\n      <td>0.807309</td>\n      <td>0.743119</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[I 2024-10-08 17:08:32,198] Trial 1 finished with value: 0.8135259356533159 and parameters: {'learning_rate': 3.106056060729316e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'num_train_epochs': 4, 'weight_decay': 0.22702882612090408}. Best is trial 0 with value: 0.8220617202889035.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.662500</td>\n      <td>0.580040</td>\n      <td>0.726855</td>\n      <td>0.684370</td>\n      <td>0.679217</td>\n      <td>0.689602</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.505600</td>\n      <td>0.450428</td>\n      <td>0.804990</td>\n      <td>0.748092</td>\n      <td>0.840000</td>\n      <td>0.674312</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[I 2024-10-08 17:10:24,698] Trial 2 finished with value: 0.8049901510177282 and parameters: {'learning_rate': 1.6811650114424644e-05, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.17264794730000776}. Best is trial 0 with value: 0.8220617202889035.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [288/288 01:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.651700</td>\n      <td>0.554487</td>\n      <td>0.740643</td>\n      <td>0.697318</td>\n      <td>0.698925</td>\n      <td>0.695719</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.489800</td>\n      <td>0.447127</td>\n      <td>0.803677</td>\n      <td>0.762887</td>\n      <td>0.792422</td>\n      <td>0.735474</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[I 2024-10-08 17:12:17,427] Trial 3 finished with value: 0.8036769533814839 and parameters: {'learning_rate': 2.1732852859885136e-05, 'per_device_train_batch_size': 32, 'per_device_eval_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.26574147870442477}. Best is trial 0 with value: 0.8220617202889035.\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='573' max='573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [573/573 02:46, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.629100</td>\n      <td>0.522670</td>\n      <td>0.756402</td>\n      <td>0.727406</td>\n      <td>0.700141</td>\n      <td>0.756881</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.463500</td>\n      <td>0.443832</td>\n      <td>0.806303</td>\n      <td>0.772902</td>\n      <td>0.778295</td>\n      <td>0.767584</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.407600</td>\n      <td>0.424560</td>\n      <td>0.826658</td>\n      <td>0.776650</td>\n      <td>0.869318</td>\n      <td>0.701835</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.379400</td>\n      <td>0.463897</td>\n      <td>0.821405</td>\n      <td>0.772194</td>\n      <td>0.853704</td>\n      <td>0.704893</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.321600</td>\n      <td>0.433273</td>\n      <td>0.822062</td>\n      <td>0.781275</td>\n      <td>0.827350</td>\n      <td>0.740061</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n[I 2024-10-08 17:15:04,762] Trial 4 finished with value: 0.8220617202889035 and parameters: {'learning_rate': 4.841185304730115e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.26655700779931013}. Best is trial 0 with value: 0.8220617202889035.\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = best_trials.hyperparameters\nprint(best_params)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:15:04.769339Z","iopub.execute_input":"2024-10-08T17:15:04.769745Z","iopub.status.idle":"2024-10-08T17:15:04.774626Z","shell.execute_reply.started":"2024-10-08T17:15:04.769710Z","shell.execute_reply":"2024-10-08T17:15:04.773808Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"{'learning_rate': 4.171479503407097e-05, 'per_device_train_batch_size': 16, 'per_device_eval_batch_size': 32, 'num_train_epochs': 4, 'weight_decay': 0.1395962005551185}\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./model',\n    warmup_steps=500,\n    logging_dir='./logs',\n    logging_steps=100,\n    eval_strategy='steps',\n    eval_steps=100,\n    save_steps=100,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    report_to='none',\n    **best_params )\n\ntrainer = Trainer(\n    model=model_init(best_trials),\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:15:33.726946Z","iopub.execute_input":"2024-10-08T17:15:33.727892Z","iopub.status.idle":"2024-10-08T17:15:34.127725Z","shell.execute_reply.started":"2024-10-08T17:15:33.727850Z","shell.execute_reply":"2024-10-08T17:15:34.126914Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()\n\ntrainer.save_model('./best_model')","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:15:36.458982Z","iopub.execute_input":"2024-10-08T17:15:36.459408Z","iopub.status.idle":"2024-10-08T17:19:14.681326Z","shell.execute_reply.started":"2024-10-08T17:15:36.459371Z","shell.execute_reply":"2024-10-08T17:19:14.680425Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='764' max='764' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [764/764 03:36, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.649600</td>\n      <td>0.494417</td>\n      <td>0.773473</td>\n      <td>0.726841</td>\n      <td>0.753695</td>\n      <td>0.701835</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.454100</td>\n      <td>0.439334</td>\n      <td>0.812869</td>\n      <td>0.775059</td>\n      <td>0.800979</td>\n      <td>0.750765</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.412000</td>\n      <td>0.411703</td>\n      <td>0.817466</td>\n      <td>0.772131</td>\n      <td>0.832155</td>\n      <td>0.720183</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.374400</td>\n      <td>0.455324</td>\n      <td>0.820749</td>\n      <td>0.775309</td>\n      <td>0.839572</td>\n      <td>0.720183</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.319800</td>\n      <td>0.434426</td>\n      <td>0.818779</td>\n      <td>0.766102</td>\n      <td>0.859316</td>\n      <td>0.691131</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.324000</td>\n      <td>0.535977</td>\n      <td>0.815496</td>\n      <td>0.768724</td>\n      <td>0.832442</td>\n      <td>0.714067</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.215700</td>\n      <td>0.547293</td>\n      <td>0.819435</td>\n      <td>0.776241</td>\n      <td>0.829565</td>\n      <td>0.729358</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model = BertForSequenceClassification.from_pretrained('./best_model')","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:20:00.376708Z","iopub.execute_input":"2024-10-08T17:20:00.377176Z","iopub.status.idle":"2024-10-08T17:20:00.461686Z","shell.execute_reply.started":"2024-10-08T17:20:00.377135Z","shell.execute_reply":"2024-10-08T17:20:00.460962Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:20:20.685226Z","iopub.execute_input":"2024-10-08T17:20:20.685901Z","iopub.status.idle":"2024-10-08T17:20:20.719059Z","shell.execute_reply.started":"2024-10-08T17:20:20.685863Z","shell.execute_reply":"2024-10-08T17:20:20.718325Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:20:23.008879Z","iopub.execute_input":"2024-10-08T17:20:23.009275Z","iopub.status.idle":"2024-10-08T17:20:23.020633Z","shell.execute_reply.started":"2024-10-08T17:20:23.009236Z","shell.execute_reply":"2024-10-08T17:20:23.019582Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df['text'] = test_df['text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:20:24.896462Z","iopub.execute_input":"2024-10-08T17:20:24.897389Z","iopub.status.idle":"2024-10-08T17:20:25.125897Z","shell.execute_reply.started":"2024-10-08T17:20:24.897339Z","shell.execute_reply":"2024-10-08T17:20:25.124940Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.drop(columns=['keyword','location'], axis=1)\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:20:56.886020Z","iopub.execute_input":"2024-10-08T17:20:56.886440Z","iopub.status.idle":"2024-10-08T17:20:56.898638Z","shell.execute_reply.started":"2024-10-08T17:20:56.886402Z","shell.execute_reply":"2024-10-08T17:20:56.897570Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"         id                                               text\n0         0                        happened terrible car crash\n1         2  heard earthquake different cities, stay safe e...\n2         3  forest fire spot pond, geese fleeing across st...\n3         9              apocalypse lighting spokane wildfires\n4        11                typhoon soudelor kills china taiwan\n...     ...                                                ...\n3258  10861  earthquake safety los angeles safety fasteners...\n3259  10865  storm ri worse last hurricane city amp others ...\n3260  10868  green line derailment chicago http tco utbxlcbiuy\n3261  10874  meg issues hazardous weather outlook hwo http ...\n3262  10875  cityofcalgary activated municipal emergency pl...\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>happened terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>heard earthquake different cities, stay safe e...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>forest fire spot pond, geese fleeing across st...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>apocalypse lighting spokane wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>typhoon soudelor kills china taiwan</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>earthquake safety los angeles safety fasteners...</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>storm ri worse last hurricane city amp others ...</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>green line derailment chicago http tco utbxlcbiuy</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>meg issues hazardous weather outlook hwo http ...</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>cityofcalgary activated municipal emergency pl...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"text = test_df['text'].values","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:29:54.258007Z","iopub.execute_input":"2024-10-08T17:29:54.258465Z","iopub.status.idle":"2024-10-08T17:29:54.263117Z","shell.execute_reply.started":"2024-10-08T17:29:54.258426Z","shell.execute_reply":"2024-10-08T17:29:54.262182Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"test_input_ids = []\ntest_attention_masks = []\nfor tweet in text:\n    encoded_dict =tokenizer(tweet,\n                add_special_tokens = True,\n                return_tensors='pt',\n                return_attention_mask=True,\n                max_length=45,\n                pad_to_max_length=True\n                )\n    test_input_ids.append(encoded_dict['input_ids'])\n    test_attention_masks.append(encoded_dict['attention_mask'])\ntest_input_ids = torch.cat(test_input_ids, dim=0)\ntest_attention_masks = torch.cat(test_attention_masks, dim=0)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:30:07.934281Z","iopub.execute_input":"2024-10-08T17:30:07.935176Z","iopub.status.idle":"2024-10-08T17:30:08.741351Z","shell.execute_reply.started":"2024-10-08T17:30:07.935131Z","shell.execute_reply":"2024-10-08T17:30:08.740280Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2837: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"test_input_ids","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:32:47.975193Z","iopub.execute_input":"2024-10-08T17:32:47.975558Z","iopub.status.idle":"2024-10-08T17:32:47.988849Z","shell.execute_reply.started":"2024-10-08T17:32:47.975526Z","shell.execute_reply":"2024-10-08T17:32:47.987905Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"tensor([[  101,  3047,  6659,  ...,     0,     0,     0],\n        [  101,  2657,  8372,  ...,     0,     0,     0],\n        [  101,  3224,  2543,  ...,     0,     0,     0],\n        ...,\n        [  101,  2665,  2240,  ...,     0,     0,     0],\n        [  101, 12669,  3314,  ...,     0,     0,     0],\n        [  101,  2103, 11253,  ...,     0,     0,     0]])"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\ntest_dataset = TensorDataset(test_input_ids,test_attention_masks)\ntest_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset),batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:33:00.942672Z","iopub.execute_input":"2024-10-08T17:33:00.943415Z","iopub.status.idle":"2024-10-08T17:33:00.948396Z","shell.execute_reply.started":"2024-10-08T17:33:00.943365Z","shell.execute_reply":"2024-10-08T17:33:00.947456Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"import numpy as np\npredictions = []\nfor index,batch in enumerate(test_dataloader):\n    b_input_ids = batch[0]\n    b_input_mask = batch[1]\n    with torch.no_grad():\n        output = best_model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n        logits = output.logits\n        logits = logits.detach().numpy()\n        pred_flat = np.argmax(logits, axis=1).flatten()\n        predictions.extend(list(pred_flat))","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:34:51.152817Z","iopub.execute_input":"2024-10-08T17:34:51.153701Z","iopub.status.idle":"2024-10-08T17:37:04.682565Z","shell.execute_reply.started":"2024-10-08T17:34:51.153658Z","shell.execute_reply":"2024-10-08T17:37:04.681499Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame()\ndf['id'] = test_df['id']\ndf['target'] = predictions\ndf.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T17:47:41.578628Z","iopub.execute_input":"2024-10-08T17:47:41.579357Z","iopub.status.idle":"2024-10-08T17:47:41.603818Z","shell.execute_reply.started":"2024-10-08T17:47:41.579301Z","shell.execute_reply":"2024-10-08T17:47:41.602918Z"},"trusted":true},"execution_count":89,"outputs":[]}]}